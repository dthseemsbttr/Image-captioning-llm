{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aac_metrics\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./models/captioning_flickr_attention_pos_embedding_results.json', 'r') as file:\n",
    "    result = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'bleu_1': tensor(0.3185, dtype=torch.float64),\n",
       "  'bleu_2': tensor(0.1528, dtype=torch.float64),\n",
       "  'bleu_3': tensor(0.1011, dtype=torch.float64),\n",
       "  'bleu_4': tensor(0.0775, dtype=torch.float64),\n",
       "  'meteor': tensor(0.2445, dtype=torch.float64)},\n",
       " {'bleu_1': tensor([0.1989, 0.1533, 0.4211,  ..., 0.1913, 1.0000, 0.5643],\n",
       "         dtype=torch.float64),\n",
       "  'bleu_2': tensor([4.7162e-09, 3.5813e-09, 2.6491e-01,  ..., 3.7036e-09, 1.0000e+00,\n",
       "          9.7743e-09], dtype=torch.float64),\n",
       "  'bleu_3': tensor([1.4167e-11, 1.0567e-11, 1.6042e-06,  ..., 1.0398e-11, 1.0000e+00,\n",
       "          2.7242e-11], dtype=torch.float64),\n",
       "  'bleu_4': tensor([8.0697e-13, 5.8933e-13, 4.0078e-09,  ..., 5.7261e-13, 1.0000e+00,\n",
       "          1.5455e-12], dtype=torch.float64),\n",
       "  'meteor': tensor([0.2026, 0.1677, 0.3191,  ..., 0.2423, 1.0000, 0.3895],\n",
       "         dtype=torch.float64)})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aac_metrics.evaluate(result['outputs'], [[x] for x in result['captions']], metrics=(\n",
    "        \"bleu_1\",\n",
    "        \"bleu_2\",\n",
    "        \"bleu_3\",\n",
    "        \"bleu_4\",\n",
    "        \"meteor\",))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10., dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aac_metrics.functional.cider_d(result['outputs'], [[x] for x in result['captions']])[1]['cider_d'].max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
