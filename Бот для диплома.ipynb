{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import razdel\n",
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import telebot\n",
    "from telebot import types\n",
    "from functools import partial\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms \n",
    "import requests\n",
    "\n",
    "\n",
    "class Vectorizer:\n",
    "    pad = \"<PAD>\"\n",
    "    unk = \"<UNK>\"\n",
    "    sos = \"<SOS>\"\n",
    "    eos = \"<EOS>\"\n",
    "\n",
    "    def __init__(self, annotations):\n",
    "\n",
    "        words_with_dot_list = annotations.apply(\n",
    "            lambda x: self.tokenize(x))\n",
    "        words_with_dot = words_with_dot_list.explode()\n",
    "        words = words_with_dot.apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "        self.counts = words.value_counts()\n",
    "        words = list(self.counts[self.counts > 2].index)\n",
    "        self.vocabulary = [Vectorizer.pad, Vectorizer.unk,\n",
    "                           Vectorizer.sos, Vectorizer.eos, *words]\n",
    "\n",
    "        text2seq = {word: i for i, word in enumerate(self.vocabulary)}\n",
    "        self.padding_idx = text2seq[Vectorizer.pad]\n",
    "        self.unknown_idx = text2seq[Vectorizer.unk]\n",
    "        self.start_of_sentance_idx = text2seq[Vectorizer.sos]\n",
    "        self.end_of_sentance_idx = text2seq[Vectorizer.eos]\n",
    "        self.text2seq = defaultdict(lambda: self.unknown_idx,  text2seq)\n",
    "        self.seq2text = {i: word for i, word in enumerate(self.vocabulary)}\n",
    "        max_len = max(words_with_dot_list.apply(lambda x: len(x)))\n",
    "        self.max_len = max_len + 2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.vocabulary)\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        text_sub = re.sub(r'[^\\w\\s]', '', text)\n",
    "        text_list = [_.text for _ in razdel.tokenize(text_sub.lower())]\n",
    "        return text_list\n",
    "\n",
    "    def encode(self, text):\n",
    "        no_pad = [self.start_of_sentance_idx] + list(map(lambda x: self.text2seq.get(\n",
    "            x, self.unknown_idx), self.tokenize(text))) + [self.end_of_sentance_idx]\n",
    "        len_pad = self.max_len - len(no_pad)\n",
    "        return torch.tensor(no_pad + [self.text2seq['<PAD>']]*len_pad)\n",
    "\n",
    "    def decode(self, encode_text):\n",
    "        with_pad = list(map(self.seq2text.get, encode_text.tolist(\n",
    "        ) if not isinstance(encode_text, list) else encode_text))\n",
    "        return ' '.join(list(filter(lambda x: x != '<PAD>', with_pad)))\n",
    "\n",
    "all_captions_path = 'C:/Users/ivanb/Downloads/Telegram Desktop/all_captions.csv'\n",
    "vectorizer = Vectorizer(pd.read_csv(all_captions_path)['translations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        self.encoder.fc = nn.Linear(self.encoder.fc.in_features, 512)\n",
    "\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            nn.Linear(256*8, 128*14*14),\n",
    "            nn.Unflatten(1, (128, 14, 14)),\n",
    "\n",
    "            nn.Upsample(scale_factor=2.0, mode='nearest'),\n",
    "\n",
    "            nn.Conv2d(128, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2.0, mode='nearest'),\n",
    "\n",
    "            nn.Conv2d(64, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2.0, mode='nearest'),\n",
    "\n",
    "            nn.Conv2d(32, 16, kernel_size=5, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2.0, mode='nearest'),\n",
    "\n",
    "            nn.ConvTranspose2d(16, 8, 3, stride=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(8, 3, 3, stride=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x) * 255\n",
    "        return x\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, encoder_dim, decoder_dim, attention_dim):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        self.attention_dim = attention_dim\n",
    "\n",
    "        self.W = nn.Linear(decoder_dim, attention_dim)\n",
    "        self.U = nn.Linear(encoder_dim, attention_dim)\n",
    "\n",
    "        self.A = nn.Linear(attention_dim, 1)\n",
    "\n",
    "    def forward(self, features, hidden_state):\n",
    "\n",
    "        u_hs = self.U(features)\n",
    "        w_ah = self.W(hidden_state)\n",
    "\n",
    "        combined_states = torch.tanh(u_hs + w_ah.unsqueeze(1))\n",
    "\n",
    "        attention_scores = self.A(combined_states)\n",
    "        attention_scores = attention_scores.squeeze(2)\n",
    "\n",
    "        alpha = F.softmax(attention_scores, dim=1)\n",
    "\n",
    "        attention_weights = features * alpha.unsqueeze(2)\n",
    "        attention_weights = attention_weights.sum(dim=1)\n",
    "\n",
    "        return alpha, attention_weights\n",
    "\n",
    "\n",
    "class AttentionDecoder(nn.Module):\n",
    "    def __init__(self, embed_size: int, hidden_size: int, encoder_size: int, attention_dim: int, vocab: Vectorizer):\n",
    "        super(AttentionDecoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            *list(Autoencoder().encoder.children())[:-2])\n",
    "\n",
    "        for param in list(self.encoder.parameters())[:-1]:\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.vocab = vocab\n",
    "        self.embedding = nn.Embedding(\n",
    "            len(self.vocab), embed_size, padding_idx=self.vocab.padding_idx)\n",
    "        self.pos_embeddings = nn.Embedding(self.vocab.max_len, embed_size)\n",
    "        self.attention = Attention(encoder_size, hidden_size, attention_dim)\n",
    "\n",
    "        self.init_h = nn.Linear(encoder_size, hidden_size)\n",
    "        self.init_c = nn.Linear(encoder_size, hidden_size)\n",
    "\n",
    "        self.lstm_cell = nn.LSTMCell(\n",
    "            embed_size+encoder_size, hidden_size, bias=True)\n",
    "        self.f_beta = nn.Linear(hidden_size, encoder_size)\n",
    "\n",
    "        self.fcn = nn.Linear(hidden_size, len(self.vocab))\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "\n",
    "    def init_hidden_state(self, encoder_out):\n",
    "        mean_encoder_out = encoder_out.mean(dim=1)\n",
    "        h = self.init_h(mean_encoder_out)\n",
    "        c = self.init_c(mean_encoder_out)\n",
    "        return h, c\n",
    "\n",
    "    def forward_step(self, decoder_input, encoder_outputs, last_hidden, last_cell, position, device='cuda:0'):\n",
    "\n",
    "        embeds = self.embedding(\n",
    "            decoder_input) + self.pos_embeddings(torch.tensor(position).long().to(device))\n",
    "        alpha, context = self.attention(encoder_outputs, last_hidden)\n",
    "\n",
    "        lstm_input = torch.cat((embeds, context), dim=1)\n",
    "\n",
    "        hidden, cell = self.lstm_cell(lstm_input, (last_hidden, last_cell))\n",
    "\n",
    "        output = self.fcn(self.drop(hidden))\n",
    "\n",
    "        return output, alpha, hidden, cell\n",
    "\n",
    "    def forward(self, imgs, decoder_input, device='cuda:0'):\n",
    "\n",
    "        encoder_outputs = self.encoder(imgs)\n",
    "        encoder_outputs = encoder_outputs.permute(0, 2, 3, 1)\n",
    "        encoder_outputs = encoder_outputs.view(\n",
    "            encoder_outputs.size(0), -1, encoder_outputs.size(3))\n",
    "\n",
    "        hidden, cell = self.init_hidden_state(encoder_outputs)\n",
    "\n",
    "        seq_length = len(decoder_input[0])\n",
    "        batch_size = decoder_input.size(0)\n",
    "        num_features = encoder_outputs.size(1)\n",
    "\n",
    "        outputs = torch.zeros(batch_size, seq_length,\n",
    "                              len(self.vocab)).to(device)\n",
    "        alphas = torch.zeros(batch_size, seq_length, num_features).to(device)\n",
    "\n",
    "        for s in range(seq_length):\n",
    "            output, alpha, hidden, cell = self.forward_step(\n",
    "                decoder_input[:, s].to(device), encoder_outputs, hidden, cell, s)\n",
    "            outputs[:, s] = output\n",
    "            alphas[:, s] = alpha\n",
    "\n",
    "        return outputs, alphas\n",
    "\n",
    "    def greedy_decode(self, imgs, device='cpu'):\n",
    "\n",
    "        encoder_outputs = self.encoder.to(device)(imgs)\n",
    "        encoder_outputs = encoder_outputs.permute(0, 2, 3, 1)\n",
    "        encoder_outputs = encoder_outputs.view(\n",
    "            encoder_outputs.size(0), -1, encoder_outputs.size(3))\n",
    "\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        hidden, cell = self.init_hidden_state(encoder_outputs)\n",
    "        decoder_input = torch.tensor(self.vocab.text2seq['<SOS>']).to(device)\n",
    "        decoder_input = torch.LongTensor([decoder_input]).to(device)\n",
    "\n",
    "        decoded_batch = [self.vocab.text2seq['<SOS>']]\n",
    "        for i in range(self.vocab.max_len):\n",
    "            decoder_output, alpha, hidden, cell = self.forward_step(\n",
    "                decoder_input, encoder_outputs, hidden, cell, i, 'cpu')\n",
    "\n",
    "            decoder_output = decoder_output.view(batch_size, -1)\n",
    "            predicted_word_idx = decoder_output.argmax(dim=1)\n",
    "            decoded_batch.append(predicted_word_idx.item())\n",
    "            if self.vocab.seq2text[predicted_word_idx.item()] == \"<EOS>\":\n",
    "                break\n",
    "            decoder_input = predicted_word_idx\n",
    "        return decoded_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttentionDecoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (embedding): Embedding(18584, 512, padding_idx=0)\n",
       "  (pos_embeddings): Embedding(69, 512)\n",
       "  (attention): Attention(\n",
       "    (W): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (U): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (A): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       "  (init_h): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (init_c): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (lstm_cell): LSTMCell(1024, 512)\n",
       "  (f_beta): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fcn): Linear(in_features=512, out_features=18584, bias=True)\n",
       "  (drop): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.Resize((224, 224))]) \n",
    "CAPTION_MODEL_weights = torch.load(\"./Caption Image/models/captioning_flickr_attention_pos_embedding_weights.pt\", map_location='cpu')\n",
    "\n",
    "\n",
    "embed_size=512\n",
    "attention_dim=512\n",
    "encoder_size=512\n",
    "hidden_size=512\n",
    "\n",
    "CAPTION_MODEL = AttentionDecoder(embed_size=embed_size, hidden_size=hidden_size, encoder_size=encoder_size, attention_dim=attention_dim, vocab=vectorizer)\n",
    "CAPTION_MODEL.load_state_dict(CAPTION_MODEL_weights)\n",
    "CAPTION_MODEL.encoder.eval()\n",
    "CAPTION_MODEL.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'result': {'alternatives': [{'message': {'role': 'assistant', 'text': 'Исходя из описания, можно предположить, что поезд едет по железнодорожным путям.\\n\\nОпределить конкретное направление движения поезда по описанию затруднительно.\\n\\nОбъект, обозначенный как <UNK>, не позволяет сделать более точный вывод о том, куда может ехать этот поезд.'}, 'status': 'ALTERNATIVE_STATUS_FINAL'}], 'usage': {'inputTextTokens': '80', 'completionTokens': '54', 'totalTokens': '134'}, 'modelVersion': '07.03.2024'}}\n",
      "{'result': {'alternatives': [{'message': {'role': 'assistant', 'text': 'Загадочный мужчина в стильном образе держит табличку с интригующей надписью. Кто знает, что там написано? Может быть, это приглашение на секретное мероприятие или просто шутка? Снимок создаёт атмосферу тайны и вызывает желание разгадать загадку. #загадочныймужчина #секрет #интрига'}, 'status': 'ALTERNATIVE_STATUS_FINAL'}], 'usage': {'inputTextTokens': '87', 'completionTokens': '60', 'totalTokens': '147'}, 'modelVersion': '07.03.2024'}}\n",
      "{'result': {'alternatives': [{'message': {'role': 'assistant', 'text': 'Посмотрите на этого смельчака! Он выполняет трюк на вершине горы в солнечный день. Кажется, что он совсем не боится высоты. Его движения уверенные и точные. Он мастер своего дела.\\n\\n#трюки #смелость #высота #горы #солнце #красота'}, 'status': 'ALTERNATIVE_STATUS_FINAL'}], 'usage': {'inputTextTokens': '82', 'completionTokens': '59', 'totalTokens': '141'}, 'modelVersion': '07.03.2024'}}\n",
      "{'result': {'alternatives': [{'message': {'role': 'assistant', 'text': 'Можно предположить, что кошка на этой картинке думает о том, что происходит в гостиной.'}, 'status': 'ALTERNATIVE_STATUS_FINAL'}], 'usage': {'inputTextTokens': '79', 'completionTokens': '18', 'totalTokens': '97'}, 'modelVersion': '07.03.2024'}}\n",
      "{'result': {'alternatives': [{'message': {'role': 'assistant', 'text': '**Вопрос**: Что заинтересовало кошку?\\n\\n**Ответ**: Возможно, кошку заинтересовала какая-то активность в гостиной, например, движение игрушки или другого животного. Она внимательно смотрит в ту сторону, словно ожидая чего-то интересного.\\n\\n**История**: Кошка сидит на столе и смотрит в гостиную. Она видит, как её хозяин играет с маленьким щенком. Щенок бегает по комнате, пытаясь поймать свой хвост. Он весело лает и виляет хвостом. Кошка наблюдает за щенком с любопытством. Она не понимает, почему щенок так радуется, но ей нравится смотреть на его игру.\\n\\n*Это лишь одна из возможных историй, которую можно придумать по описанию картинки. В реальности кошка может смотреть на что-то другое, что не было распознано нейросетью.*'}, 'status': 'ALTERNATIVE_STATUS_FINAL'}], 'usage': {'inputTextTokens': '83', 'completionTokens': '157', 'totalTokens': '240'}, 'modelVersion': '07.03.2024'}}\n",
      "{'result': {'alternatives': [{'message': {'role': 'assistant', 'text': '**История, о которой может думать кошка со стола:**\\n\\nКошка сидит на столе и с любопытством смотрит в гостиную. Она видит, как её хозяин увлечённо играет в видеоигру. Кошка знает, что это занятие может быть очень увлекательным, и ей интересно, что же так привлекает хозяина.\\n\\nВозможно, кошка думает о том, как было бы здорово присоединиться к игре. Она представляет, как прыгает на клавиатуру и пытается поймать курсор. Но она знает, что это не понравится хозяину, и остаётся на месте.\\n\\nВместо этого кошка решает просто наблюдать за игрой. Она уверена, что хозяин оценит её поддержку и будет рад, что она рядом.'}, 'status': 'ALTERNATIVE_STATUS_FINAL'}], 'usage': {'inputTextTokens': '83', 'completionTokens': '135', 'totalTokens': '218'}, 'modelVersion': '07.03.2024'}}\n",
      "{'result': {'alternatives': [{'message': {'role': 'assistant', 'text': 'Посмотрите, как человек выполняет невероятный трюк на вершине горы! Яркое солнце освещает его смелое выступление. Это точно заслуживает вашего внимания!'}, 'status': 'ALTERNATIVE_STATUS_FINAL'}], 'usage': {'inputTextTokens': '82', 'completionTokens': '29', 'totalTokens': '111'}, 'modelVersion': '07.03.2024'}}\n",
      "{'result': {'alternatives': [{'message': {'role': 'assistant', 'text': 'Он может думать о том, что видит в гостиной. Возможно, его внимание привлёк какой-то предмет или движение.'}, 'status': 'ALTERNATIVE_STATUS_FINAL'}], 'usage': {'inputTextTokens': '81', 'completionTokens': '25', 'totalTokens': '106'}, 'modelVersion': '07.03.2024'}}\n"
     ]
    },
    {
     "ename": "ReadTimeout",
     "evalue": "HTTPSConnectionPool(host='api.telegram.org', port=443): Read timed out. (read timeout=25)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\urllib3\\connectionpool.py:537\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 537\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\urllib3\\connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 461\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\http\\client.py:1386\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1385\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1386\u001b[0m     response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\http\\client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\http\\client.py:286\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 286\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\ssl.py:1315\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1312\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1313\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1314\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mTimeoutError\u001b[0m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\urllib3\\connectionpool.py:845\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    843\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[1;32m--> 845\u001b[0m retries \u001b[38;5;241m=\u001b[39m retries\u001b[38;5;241m.\u001b[39mincrement(\n\u001b[0;32m    846\u001b[0m     method, url, error\u001b[38;5;241m=\u001b[39mnew_e, _pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, _stacktrace\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    847\u001b[0m )\n\u001b[0;32m    848\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\urllib3\\util\\retry.py:470\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method_retryable(method):\n\u001b[1;32m--> 470\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m reraise(\u001b[38;5;28mtype\u001b[39m(error), error, _stacktrace)\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\urllib3\\util\\util.py:39\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\urllib3\\connectionpool.py:791\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 791\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    792\u001b[0m     conn,\n\u001b[0;32m    793\u001b[0m     method,\n\u001b[0;32m    794\u001b[0m     url,\n\u001b[0;32m    795\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    796\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    797\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    798\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    799\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    800\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    801\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    802\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    803\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    804\u001b[0m )\n\u001b[0;32m    806\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\urllib3\\connectionpool.py:539\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\urllib3\\connectionpool.py:371\u001b[0m, in \u001b[0;36mHTTPConnectionPool._raise_timeout\u001b[1;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, SocketTimeout):\n\u001b[1;32m--> 371\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;28mself\u001b[39m, url, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead timed out. (read timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    373\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;66;03m# See the above comment about EAGAIN in Python 3.\u001b[39;00m\n",
      "\u001b[1;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='api.telegram.org', port=443): Read timed out. (read timeout=25)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 80\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28mprint\u001b[39m(responce\u001b[38;5;241m.\u001b[39mjson())\n\u001b[0;32m     78\u001b[0m     bot\u001b[38;5;241m.\u001b[39msend_message(call\u001b[38;5;241m.\u001b[39mfrom_user\u001b[38;5;241m.\u001b[39mid, responce\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malternatives\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m])    \n\u001b[1;32m---> 80\u001b[0m bot\u001b[38;5;241m.\u001b[39mpolling(none_stop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\telebot\\__init__.py:1169\u001b[0m, in \u001b[0;36mTeleBot.polling\u001b[1;34m(self, non_stop, skip_pending, interval, timeout, long_polling_timeout, logger_level, allowed_updates, none_stop, restart_on_change, path_to_watch)\u001b[0m\n\u001b[0;32m   1166\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStarting your bot with username: [@\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser\u001b[38;5;241m.\u001b[39musername)\n\u001b[0;32m   1168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreaded:\n\u001b[1;32m-> 1169\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__threaded_polling(non_stop\u001b[38;5;241m=\u001b[39mnon_stop, interval\u001b[38;5;241m=\u001b[39minterval, timeout\u001b[38;5;241m=\u001b[39mtimeout, long_polling_timeout\u001b[38;5;241m=\u001b[39mlong_polling_timeout,\n\u001b[0;32m   1170\u001b[0m                             logger_level\u001b[38;5;241m=\u001b[39mlogger_level, allowed_updates\u001b[38;5;241m=\u001b[39mallowed_updates)\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__non_threaded_polling(non_stop\u001b[38;5;241m=\u001b[39mnon_stop, interval\u001b[38;5;241m=\u001b[39minterval, timeout\u001b[38;5;241m=\u001b[39mtimeout, long_polling_timeout\u001b[38;5;241m=\u001b[39mlong_polling_timeout,\n\u001b[0;32m   1173\u001b[0m                                 logger_level\u001b[38;5;241m=\u001b[39mlogger_level, allowed_updates\u001b[38;5;241m=\u001b[39mallowed_updates)\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\telebot\\__init__.py:1244\u001b[0m, in \u001b[0;36mTeleBot.__threaded_polling\u001b[1;34m(self, non_stop, interval, timeout, long_polling_timeout, logger_level, allowed_updates)\u001b[0m\n\u001b[0;32m   1242\u001b[0m     polling_thread\u001b[38;5;241m.\u001b[39mclear_exceptions()   \u001b[38;5;66;03m#*\u001b[39;00m\n\u001b[0;32m   1243\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworker_pool\u001b[38;5;241m.\u001b[39mclear_exceptions() \u001b[38;5;66;03m#*\u001b[39;00m\n\u001b[1;32m-> 1244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1246\u001b[0m     polling_thread\u001b[38;5;241m.\u001b[39mclear_exceptions()\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\telebot\\__init__.py:1205\u001b[0m, in \u001b[0;36mTeleBot.__threaded_polling\u001b[1;34m(self, non_stop, interval, timeout, long_polling_timeout, logger_level, allowed_updates)\u001b[0m\n\u001b[0;32m   1203\u001b[0m polling_thread\u001b[38;5;241m.\u001b[39mput(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__retrieve_updates, timeout, long_polling_timeout, allowed_updates\u001b[38;5;241m=\u001b[39mallowed_updates)\n\u001b[0;32m   1204\u001b[0m or_event\u001b[38;5;241m.\u001b[39mwait()  \u001b[38;5;66;03m# wait for polling thread finish, polling thread error or thread pool error\u001b[39;00m\n\u001b[1;32m-> 1205\u001b[0m polling_thread\u001b[38;5;241m.\u001b[39mraise_exceptions()\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworker_pool\u001b[38;5;241m.\u001b[39mraise_exceptions()\n\u001b[0;32m   1207\u001b[0m error_interval \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.25\u001b[39m\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\telebot\\util.py:111\u001b[0m, in \u001b[0;36mWorkerThread.raise_exceptions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_exceptions\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexception_event\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[1;32m--> 111\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexception_info\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\telebot\\util.py:93\u001b[0m, in \u001b[0;36mWorkerThread.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     90\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived task\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreceived_task_event\u001b[38;5;241m.\u001b[39mset()\n\u001b[1;32m---> 93\u001b[0m task(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     94\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTask complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone_event\u001b[38;5;241m.\u001b[39mset()\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\telebot\\__init__.py:675\u001b[0m, in \u001b[0;36mTeleBot.__retrieve_updates\u001b[1;34m(self, timeout, long_polling_timeout, allowed_updates)\u001b[0m\n\u001b[0;32m    673\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSkipped all pending messages\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m updates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_updates(offset\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_update_id \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \n\u001b[0;32m    676\u001b[0m                            allowed_updates\u001b[38;5;241m=\u001b[39mallowed_updates,\n\u001b[0;32m    677\u001b[0m                            timeout\u001b[38;5;241m=\u001b[39mtimeout, long_polling_timeout\u001b[38;5;241m=\u001b[39mlong_polling_timeout)\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_new_updates(updates)\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\telebot\\__init__.py:647\u001b[0m, in \u001b[0;36mTeleBot.get_updates\u001b[1;34m(self, offset, limit, timeout, allowed_updates, long_polling_timeout)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_updates\u001b[39m(\u001b[38;5;28mself\u001b[39m, offset: Optional[\u001b[38;5;28mint\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, limit: Optional[\u001b[38;5;28mint\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \n\u001b[0;32m    618\u001b[0m         timeout: Optional[\u001b[38;5;28mint\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, allowed_updates: Optional[List[\u001b[38;5;28mstr\u001b[39m]]\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \n\u001b[0;32m    619\u001b[0m         long_polling_timeout: \u001b[38;5;28mint\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[types\u001b[38;5;241m.\u001b[39mUpdate]:\n\u001b[0;32m    620\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;124;03m    Use this method to receive incoming updates using long polling (wiki). An Array of Update objects is returned.\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    645\u001b[0m \u001b[38;5;124;03m    :rtype: :obj:`list` of :class:`telebot.types.Update`\u001b[39;00m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 647\u001b[0m     json_updates \u001b[38;5;241m=\u001b[39m apihelper\u001b[38;5;241m.\u001b[39mget_updates(\n\u001b[0;32m    648\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken, offset\u001b[38;5;241m=\u001b[39moffset, limit\u001b[38;5;241m=\u001b[39mlimit, timeout\u001b[38;5;241m=\u001b[39mtimeout, allowed_updates\u001b[38;5;241m=\u001b[39mallowed_updates,\n\u001b[0;32m    649\u001b[0m         long_polling_timeout\u001b[38;5;241m=\u001b[39mlong_polling_timeout)\n\u001b[0;32m    650\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [types\u001b[38;5;241m.\u001b[39mUpdate\u001b[38;5;241m.\u001b[39mde_json(ju) \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m json_updates]\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\telebot\\apihelper.py:327\u001b[0m, in \u001b[0;36mget_updates\u001b[1;34m(token, offset, limit, timeout, allowed_updates, long_polling_timeout)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allowed_updates \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# Empty lists should pass\u001b[39;00m\n\u001b[0;32m    326\u001b[0m     payload[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallowed_updates\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(allowed_updates)\n\u001b[1;32m--> 327\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _make_request(token, method_url, params\u001b[38;5;241m=\u001b[39mpayload)\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\telebot\\apihelper.py:161\u001b[0m, in \u001b[0;36m_make_request\u001b[1;34m(token, method_name, method, params, files)\u001b[0m\n\u001b[0;32m    157\u001b[0m     result \u001b[38;5;241m=\u001b[39m http\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m    158\u001b[0m         method, request_url, params\u001b[38;5;241m=\u001b[39mparams, files\u001b[38;5;241m=\u001b[39mfiles,\n\u001b[0;32m    159\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m(connect_timeout, read_timeout), proxies\u001b[38;5;241m=\u001b[39mproxy)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     result \u001b[38;5;241m=\u001b[39m _get_req_session()\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m    162\u001b[0m         method, request_url, params\u001b[38;5;241m=\u001b[39mparams, files\u001b[38;5;241m=\u001b[39mfiles,\n\u001b[0;32m    163\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m(connect_timeout, read_timeout), proxies\u001b[38;5;241m=\u001b[39mproxy)\n\u001b[0;32m    165\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe server returned: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(result\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m    167\u001b[0m json_result \u001b[38;5;241m=\u001b[39m _check_result(method_name, result)\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\requests\\adapters.py:532\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[1;32m--> 532\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, _InvalidHeader):\n\u001b[0;32m    534\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidHeader(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[1;31mReadTimeout\u001b[0m: HTTPSConnectionPool(host='api.telegram.org', port=443): Read timed out. (read timeout=25)"
     ]
    }
   ],
   "source": [
    "bot = telebot.TeleBot('7090775661:AAHIZsPF22Dn2_9_5ls_iIFUnNO0jq0gc28')\n",
    "\n",
    "@bot.message_handler(commands=['start'])\n",
    "def start(message):\n",
    "    bot.send_message(message.chat.id, 'Привет! Я - модель глубокого обучения, созданная для описания изображений')\n",
    "    markup_inline = types.InlineKeyboardMarkup()\n",
    "    caption = types.InlineKeyboardButton(text = 'Описание фотографии', callback_data = 'caption')\n",
    "    llm = types.InlineKeyboardButton(text = 'Спросить у Yandex-GPT', callback_data = 'llm')\n",
    "    markup_inline.add(caption, llm)\n",
    "    bot.send_message(message.chat.id, 'Что Вы хотите сделать?', reply_markup=markup_inline)\n",
    "\n",
    "@bot.callback_query_handler(func=lambda call: 'caption' in call.data)   \n",
    "def call_caption(call):\n",
    "    action = 'описание'\n",
    "    msg = bot.send_message(call.from_user.id, 'Пришлите фото')\n",
    "    tensor = bot.register_next_step_handler(msg, partial(get_photo, call, action))\n",
    "    \n",
    "@bot.callback_query_handler(func=lambda call: 'llm' in call.data)   \n",
    "def call_caption(call):\n",
    "    action = 'вопрос'\n",
    "    msg = bot.send_message(call.from_user.id, 'Пришлите фото')\n",
    "    bot.register_next_step_handler(msg, partial(get_photo, call, action))\n",
    "    \n",
    "def get_photo(call, action, message):\n",
    "    fileID = message.photo[-1].file_id   \n",
    "    file_info = bot.get_file(fileID)\n",
    "    downloaded_file = bot.download_file(file_info.file_path)\n",
    "    with open(\"image.jpg\", 'wb') as new_file:\n",
    "        new_file.write(downloaded_file)\n",
    "    image = torchvision.io.read_image('image.jpg') \n",
    "    img_tensor = transform(image)\n",
    "    if action == 'описание':\n",
    "        make_caption(call, img_tensor)\n",
    "    elif action == 'вопрос':\n",
    "        msg = bot.send_message(call.from_user.id, 'Какой вопрос вы хотите задать?')\n",
    "        bot.register_next_step_handler(msg, partial(ask_llm, call, img_tensor))\n",
    "\n",
    "def make_caption(call, img_tensor):\n",
    "    caption_ready = CAPTION_MODEL.greedy_decode(img_tensor.float().unsqueeze(0))\n",
    "    bot.send_message(call.from_user.id, vectorizer.decode(caption_ready[1:-1]))\n",
    "\n",
    "def ask_llm(call, img_tensor, message):\n",
    "    question = message.text\n",
    "    caption_ready = CAPTION_MODEL.greedy_decode(img_tensor.float().unsqueeze(0))\n",
    "    ask_to_llm(call, vectorizer.decode(caption_ready[1:-1]), question)\n",
    "    \n",
    "def ask_to_llm(call, caption, question):\n",
    "    # api_key = 'AQVNw8Q_Vhgtj0fvm1g5qfS9vhGQ96UvlsVADQrb'\n",
    "    api_key = 'AQVN1wuefTqX_WAQa6YAvx4mduQtzaX1OAXOcso2'\n",
    "\n",
    "    url = \"https://llm.api.cloud.yandex.net/foundationModels/v1/completion\"\n",
    "\n",
    "    headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": \"Api-Key {0}\".format(api_key)\n",
    "    }\n",
    "\n",
    "    json_body = {\n",
    "      \"modelUri\": \"gpt://b1gnc3j9s2j025i5f63o/yandexgpt/latest\",\n",
    "      \"completionOptions\": {\n",
    "        \"stream\": False,\n",
    "        \"temperature\": 0.15,\n",
    "        \"maxTokens\": 300\n",
    "      },\n",
    "      \"messages\": [\n",
    "        {\n",
    "          \"role\": \"system\",\n",
    "          \"text\": \"Тебе на вход поступит вопрос и описание картинки, полученное с помощью другой нейросети Image Captioning. Постарайся максимально точно ответить на вопрос о картинке исходя из её описания. Не обязательно использовать все распознанные объекты на изображении для формирования ответа.\"\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"text\": f\"{question}\\nОписание картинки: {caption}\"\n",
    "        }\n",
    "      ]\n",
    "    }   \n",
    "    responce = requests.post(url, headers=headers, json=json_body)\n",
    "    print(responce.json())\n",
    "    bot.send_message(call.from_user.id, responce.json()['result']['alternatives'][0]['message']['text'])    \n",
    "    \n",
    "bot.polling(none_stop=True, interval=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
